---
title: "Model"
author: "Ivan Specht"
date: "4/6/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

ACT ONE: preliminaries

Scene 1. Load and clean data
```{r}
library(igraph)
library(lubridate)
library(Rfast)
library(mixdist)
library(parallel)
library(ggplot2)
library(scales)

setwd("~/Desktop/OO-modeling/")

data <- read.csv("./histories_CMU.csv")
leger <- read.csv("./participants_CMU.csv")

leger[,"p2p_id"] <- paste(leger[,"p2p_id"])
data[,"peer_id"] <- paste(data[,"peer_id"])

contacts <- subset(data, type == "contact")
contacts$contact_length <- round(milliseconds(contacts$contact_length))
end_time <- contacts$time + contacts$contact_length
contacts <- contacts[, c("user_id", "peer_id", "time")]
contacts <- cbind(contacts, end_time)

convert_peer_ID <- function(x, leger){
  return(leger[which(leger[,"p2p_id"] == x), "id"][1])
}

contacts[,"peer_id"] <- sapply(contacts[,"peer_id"], convert_peer_ID, leger = leger)

contacts$time <- as.POSIXct(contacts$time, origin = "1970-01-01", tz = "America/Denver")
contacts$end_time <- as.POSIXct(contacts$end_time, origin = "1970-01-01", tz = "America/Denver")

lower <- pmin(contacts$user_id, contacts$peer_id)
upper <- pmax(contacts$user_id, contacts$peer_id)

contacts$user_id <- lower
contacts$peer_id <- upper

contacts <- contacts[with(contacts, order(user_id, peer_id, time)), ]

gap <- 30 #seconds

i=2
while (i < nrow(contacts)) {
  if(
    contacts[i,"user_id"] == contacts[i-1,"user_id"] & 
    contacts[i,"peer_id"] == contacts[i-1,"peer_id"] & 
    contacts[i,"time"] < (contacts[i-1,"end_time"] + gap)
  ){
    contacts[i-1, "end_time"] <- max(contacts[i-1, "end_time"], contacts[i, "end_time"])
    contacts <- contacts[-i, ]
  }else{
    i <- i+1
  }
}

contacts <- contacts[with(contacts, order(time)), ]
row.names(contacts) <- 1:nrow(contacts)
duration <- contacts$end_time - contacts$time
contacts <- cbind(contacts, duration)
```

Scene 2. Process "contacts" into time series data useful for epi
```{r}
min_duration <- 60 #seconds
ts <- subset(contacts, duration >= min_duration)

# Escapees
escape <- subset(data, out == "ESCAPED")
escape <- escape[, c("user_id", "time")]
escape$time <- as.POSIXct(escape$time, origin = "1970-01-01", tz = "America/Denver")
escape <- escape[order(escape$time),]
row.names(escape) <- 1:nrow(escape)

# Time info for escape

start = as.POSIXct(min(contacts$time), origin = "1970-01-01", tz = "America/Denver")

# get 1 week of contact data
end <- start + weeks(1)

escapees <- escape$user_id[escape$time < end]

# full users
users <- leger$id


ts <- subset(ts, (user_id %in% users & peer_id %in% users))
ts <- subset(ts, time < end)

# convert to 1-week format

ts$time <- difftime(ts$time, start, units = "secs")
ts$end_time <- difftime(ts$end_time, start, units = "secs")

for (i in which(ts$end_time > 604800)) {
  old <- ts[i,]
  ts$end_time[i] <- 604800
  ts$duration[i] <- 604800 - ts$time[i]
  old$time = 0
  old$end_time <- old$end_time - 604800
  old$duration <- old$end_time
  ts <- rbind(ts, old)
}

ts <- ts[order(ts$time),]
row.names(ts) <- 1:nrow(ts)

ts$time <- seconds(ts$time)
ts$end_time <- seconds(ts$end_time)
```

ACT TWO.

Scene 1. show proportionate mixing assumption (fairly) valid
```{r}

# Adjacency matrix of total duration of contact(s)
real_adj <- matrix(0, nrow = length(users), ncol = length(users))

for (i in 1:length(users)) {
  for (j in i:length(users)) {
    sub <- subset(
      ts,
      (user_id == users[i] & peer_id == users[j]) | (user_id == users[j] & peer_id == users[i])
    )
    real_adj[i,j] <- sum(sub$duration)
    real_adj[j,i] <- sum(sub$duration)
  }
}

# Binary adjacency matrix
bin_adj <- real_adj > 0

# Node degrees
deg <- colsums(bin_adj)

# Predicted adjacency matrix under proportionate mixing, up to a constant
pred_adj <- outer(deg,deg)/sum(deg)
diag(pred_adj) <- 0

# Convert to numeric form...
preds <- as.numeric(pred_adj)
deps <- as.numeric(bin_adj)

# Linear model: decent R^2, low p-value
lmod <- lm(deps~preds+0)
summary(lmod)

# High correlation:
cor(preds, deps)

```

Scene 2: show low correlation between degree and length of contact

```{r}
# predictor variables: proportionate mixing, filtered for nonzero contact length
preds2 <- preds[deps>0]

# predictee variables: total duration of contact, filtered for nonzero contact length
deps2 <- as.numeric(real_adj)[deps>0]

# Linear model: low R^2
lmod2 <- lm(deps2~preds2+0)
summary(lmod2)

# Abysmal correlation
cor(preds2, deps2)
```

ACT THREE. Stochastic bootstrap model.

Scene 1: create bootstrap sampling function for contact times
```{r}
sim_duration <- 4 # WEEKS!!!!
sim_duration_secs <- sim_duration*60*60*24*7

edgelist <- unique(ts[,1:2])
row.names(edgelist) <- 1:nrow(edgelist)

c_start <- list()
c_end <- list()

total_time <- c()

for (i in 1:nrow(edgelist)) {
  sub <- subset(ts, user_id == edgelist[i,1] & peer_id == edgelist[i,2])
  c_start[[i]] <- as.numeric(sub$time + rep(seconds(weeks(0:(sim_duration - 1))), each = nrow(sub)))
  c_end[[i]] <- as.numeric(sub$end_time + rep(seconds(weeks(0:(sim_duration - 1))), each = nrow(sub)))
  total_time[i] <- sum(c_end[[i]] - c_start[[i]])/sim_duration_secs
}

# v0 is infection time of infector
# i is index of edge contact times

wpar1 <- as.numeric(weibullpar(5, 1.9)[1])
wpar2 <- as.numeric(weibullpar(5, 1.9)[2])

# get time of transmission via UoU with restricted domain
get_time <- function(pstarts, pends, int){
  
  if(length(pstarts) > 1){
    breaks <- pstarts - c(0, pends[1:(length(pends) - 1)])
  }else{
    breaks <- pstarts
  }
  
  divs <- pstarts - cumsum(breaks)
  
  pick <- runif(1, 0, int)
  adj_pick <- pick + sum(breaks[which(divs < pick)])
  
  return(
    qweibull(adj_pick, wpar1, wpar2) * 86400
  )
}

# returns Inf if no transmission occurs
transmission_time <- function(v0, i){
  
  # convert to days
  starts <- (c_start[[i]] - v0)/86400
  ends <- (c_end[[i]] - v0)/86400
  
  pstarts <- pweibull(starts, wpar1, wpar2)
  pends <- pweibull(ends, wpar1, wpar2)
  
  int <- sum(pends - pstarts)
  
#  prob <- lambda*int*rbeta(1,alpha,beta)/psi
  prob <- lambda*int*2*rbinom(1,1,0.5)
  
  if(runif(1) < prob){
    return(
      round(
        get_time(pstarts = pstarts, pends = pends, int = int)
      ) + v0
    )
  }else{
    return(Inf)
  }
}

# Stochastic function that spreads virus to neighbors (or doesn't)
spread <- function(v0, neighbors){
  # uniformly sample a time series for each neighbor, i.e. bootstrap
  indices <- sample(1:nrow(edgelist), size = length(neighbors), replace = TRUE)
  sapply(indices, transmission_time, v0 = v0)
}

# Get neighbors stochastically. we only care about the ones who aren't vaccinated.
get_neighbors <- function(i0, activity, sum_activity){
  which(runif(N) < ((activity[i0] * activity / sum_activity) * (1 - vaxed)))
}


```

Scene 2: Outbreak setup
```{r}
N = 6000

# probability of someone's neighbor being included in sample - original BYU data
p0 <- 1/3

# mean + variance in contacts - full sim - baseline
mu_0 = mean(deg)/p0
sigma2_0 <- (var(deg) - p0*(1-p0)*mu_0)/p0^2

# p parameter for number of contacts
p_contact_dist <- mu_0/sigma2_0

# r parameter for number of contacts
r_contact_dist <- mu_0^2 / (sigma2_0 - mu_0)

# Calibrate lambda. First we need to find the average probability of transmission.

R0 = 1

lambda <- R0/(((sigma2_0 + mu_0^2)/mu_0 - 1) * mean(total_time))

### Overdispersion - broken :(

## Compute current overdispersion based on contacts. See mathematica PGF nb for derivation.

# psi = probability of transmission given contact
psi <- mean(total_time)*lambda

var_transmissions <- psi*(1-psi)*(1-p_contact_dist)*(1+r_contact_dist)/p_contact_dist + (psi^2)*(1-p_contact_dist)*(1+r_contact_dist)/(p_contact_dist^2)

# target variance
v = 8

mom2 <- (p_contact_dist^2*v + (-1 + p_contact_dist)*p_contact_dist*(1 + r_contact_dist)*psi + (-1 + p_contact_dist)*(1 + r_contact_dist)*(-2 + p_contact_dist + (-1 + p_contact_dist)*r_contact_dist)*psi^2)/((-1 + p_contact_dist)*(1 + r_contact_dist)*(-3 - r_contact_dist + p_contact_dist*(2 + r_contact_dist)))

alpha <- ((-mom2)*psi + psi^2)/(mom2 - psi^2)
beta <- ((mom2 - psi)*(-1 + psi))/(mom2 - psi^2)


tries <- rlnorm(100000, -.5, sqrt(.5*2))
mean(tries)
var(tries)


#######-----

# get new params if people are interacting more
p <- p0

# mean + variance in contacts under new value of p
mu = mean(deg)/p
sigma2 <- (var(deg) - p*(1-p)*mu)/p^2

# get gamma params
shape <- mu^2/(sigma2 - mu)
rate <- mu/(sigma2 - mu)

# get beta hyperparams on probability 


# probability of being vaccinated
### SET A PRIOR ON THIS LATER
p_vax <- 0



```

Scene 3. OUTBREAK!!!
```{r}

outbreak <- function(idfk) {
  
  # who is vaccinated?
  vaxed <- rbinom(N, 1, p_vax)

  # infection status for each agent (binary)
  inft <- rep(0, N)
  
  # infection time for each agent (seconds)
  inft_time <- rep(Inf, N)
  
  # who we already spread
  checklist <- rep(0, N)
  
  # adjacency
  #sim_edgelist <- matrix(nrow = 0, ncol = 2)
  
  
  activity <- rgamma(N, shape = shape, rate = rate)
  sum_activity <- sum(activity)
  
  seed <- sample(N, 1, prob = activity*(1-vaxed))
  inft[seed] <- 1
  inft_time[seed] <- 0
  
  first = TRUE
  
  while (sum(inft) > sum(checklist)) {
    who <- which((inft - checklist) == 1)
    #print(who)
    
    all_v0 <- inft_time[who]
    neighbors <- lapply(who, get_neighbors, activity = activity, sum_activity = sum_activity)
    
    transmit_times <- mapply(spread, all_v0, neighbors, SIMPLIFY = FALSE)
    
    for (i0 in 1:length(who)) {
      
      #secondaries <- neighbors[[i0]][which(transmit_times[[i0]] < inft_time[neighbors[[i0]]])]
      
      inft_time[neighbors[[i0]]] <- pmin(inft_time[neighbors[[i0]]], transmit_times[[i0]])
      
      #newmtx <- matrix(c(rep(i0, length(secondaries)), secondaries), ncol = 2)
      #sim_edgelist <- rbind(sim_edgelist, newmtx)
      
      inft[which(inft_time < sim_duration_secs)] <- 1
    }
    checklist[who] <- 1
    
    if(first == TRUE){
      repro <- sum(inft) - 1
      first <- FALSE
    }
  }
  
  # get total infections after 4 weeks
  return(c(repro, sum(inft)))

}

```

Scene 4. MC simulation.

```{r}

results <- matrix(unlist(mclapply(1:10000, outbreak, mc.cores = 12)), ncol = 2, byrow = TRUE)

```

Scene 5. summary stats
```{r}

R_eff <- mean(results[,1])
R_sd <- sd(results[,1])

mean_cumulative <- mean(results[,2])
median_cumulative <- median(results[,2])
cri_cumulative <- quantile(results[,2], c(0.025, 0.975), type = 1)

R_eff
R_sd^2

mean_cumulative
median_cumulative
cri_cumulative

# Estimate overdispersion

lik <- function(params, deg){
  -sum(log(dnbinom(deg, params[1], params[2])))
}

est <- suppressWarnings(
  nlm(lik, p = c(mean(results[,1])^2/(var(results[,1]) - mean(results[,1])), mean(results[,1])/var(results[,1])), deg=results[,1])
)


```

ACT FOUR: Visualization

Visuals list:
- Act 1 viz:
1-- hist numbers of contacts (+ NBin/Bin mixed stat model?)
2-- hist durations of contacts
3-- hist total duration of contacts by person
4-- hist time of contact

- Act 2 viz:
5-- actual contact graph vs. generated contact graph (+ summary stats)

- Act 3 viz:
6-- representative transmission tree
7-- hist of 4-week case counts


Scene 1: number of contacts
```{r}

deg2 <- c()
for(i in 1:length(users)){
  deg2[i] <- sum(rowsums(bin_adj[-i, which(bin_adj[i,] == 1), drop = FALSE]) > 0)
}

dat <- data.frame(Contacts = c(deg, deg2), Degree = c(rep("First-degree", length(users)), rep("Second-degree", length(users))))

ggplot(dat, aes(x=Contacts, fill=Degree)) +
  geom_histogram(alpha=0.5, breaks = seq(0,236,4), position = "identity") + 
  labs(
    title = "First- and Second-Degree Contacts, CMU",
    x = "Contacts",
    y = "Frequency"
  ) + scale_color_brewer(palette="Dark2") + scale_fill_brewer(palette="Dark2") +
theme_minimal()

```
Scene 1.5: scatterplot first/second degree
```{r}



# probability that you're a 2nd-degree contact: 1 - (1-p)^x
# expected 2nd-deg contacts: (n-1)*(1 - (1-p)^x)

get_p <- function(params){
  mean((deg2 - params[1] * (1 - exp(-deg * params[2])))^2)
}

best_p <- optim(c(235,0.08), get_p)$par

RMSE <- sqrt(get_p(best_p))

mod_fn <- function(x){
  best_p[1] * (1 - (1 - best_p[2])^x)
}

dat2 <- data.frame(x = deg, y = deg2)

ggplot(dat2, aes(x=x,y=y)) +
  geom_point() + 
  geom_function(fun = mod_fn, color = "red") + 
  theme_minimal() +
  labs(
    title = "First- and Second-Degree Contacts, CMU",
    x = "First-Degree Contacts",
    y = "Second-Degree Contacts"
  )

RMSE

```
Scene 1.6: 1st/2nd time weighted
```{r}


# probability that you're a 2nd-degree contact: 1 - (1-p)^x
# expected 2nd-deg contacts: (n-1)*(1 - (1-p)^x)

mat2 <- real_adj %*% real_adj
diag(mat2) <- 0

dat3 <- data.frame(x = colsums(real_adj), y = colsums(mat2))

ggplot(dat3, aes(x=x,y=y)) +
  geom_point() + 
  geom_smooth(method=lm, formula = y~x+0, se=FALSE) + 
  theme_minimal() +
  labs(
    title = "Time-Weighted First- and Second-Degree Contacts, CMU",
    x = "Duration, First-Degree Contacts (seconds)",
    y = "Duration, Second-Degree * First-Degree Contacts (seconds)"
  )

summary(lm(colsums(mat2) ~ colsums(real_adj)+ 0))


load("./final.RData")

# equal weight
summary(lm(final ~ deg[deg!=0] + 0))

# duration weight
summary(lm(final ~ colsums(real_adj)[colsums(real_adj) > 0] + 0))

# kickass one
summary(lm(final ~ colsums(real_adj)[colsums(real_adj) > 0] + colsums(mat2)[colsums(real_adj) > 0] + 0))

# correlated residuals

cor.test(residuals(lm(colsums(mat2) ~ colsums(real_adj)+ 0))[colsums(real_adj) > 0], final)


```




Scene 2: durations of contacts
```{r}

ggplot(data.frame(t = as.numeric(ts$duration)), aes(x=t)) + 
  geom_histogram(breaks = seq(0,100000, 1000)) + 
  labs(
    title = "Duration of Contact, CMU",
    x = "Time (seconds)",
    y = "Frequency"
  )

# parameter estimation

#lik <- function(params, deg){
#  -sum(log(dnbinom(deg, params[1], params[2])))
#}

#est <- suppressWarnings(
  #nlm(lik, p = c(mean(deg)^2/(var(deg) - mean(deg)), mean(deg)/var(deg)), deg=deg)
#)

```


Scene 3: total duration of all contacts by person

```{r}

ggplot(data.frame(t = colsums(real_adj)[colsums(real_adj) != 0]), aes(x=t)) + 
  geom_histogram(breaks = seq(0,500000, 5000)) + 
  labs(
    title = "Total Duration of all Contacts by Person, CMU",
    x = "Time (seconds)",
    y = "Frequency"
  )

```
Scene 4: when people are interacting
```{r}
hour_interactions <- c()
hour_breaks <- seconds(seq(0, 5.5*24*60*60, 3600))
for (i in 2:length(hour_breaks)) {
  sub <- subset(ts, hour_breaks[i-1] <= time & time < hour_breaks[i])
  sub <- unique(sub[,1:2])
  hour_interactions[i-1] <- nrow(sub)
}

timebins <- start + hour_breaks[1:(length(hour_breaks) - 1)]

ggplot(data.frame(t = timebins, count = hour_interactions), aes(x=t, y = count)) + 
  geom_line() + 
  labs(
    title = "Timing of Interactions, CMU",
    x = "Time",
    y = "Number of Interactions"
  ) + 
  scale_x_datetime(breaks = date_breaks(width = "1 day"), date_labels = "%a %h %d") + 
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) 


```




Scene 5: actual graph vs. predicted graph example

```{r}
toy_adj <- pred_adj
binaries <- runif(nrow(toy_adj) * (nrow(toy_adj) - 1) / 2) < upper_tri(toy_adj)
toy_adj[upper.tri(toy_adj)] <- binaries
toy_adj <- t(toy_adj)
toy_adj[upper.tri(toy_adj)] <- binaries

toy_g <- graph_from_adjacency_matrix(toy_adj[colsums(toy_adj) > 0, colsums(toy_adj) > 0], mode = "undirected")
real_g <- graph_from_adjacency_matrix(bin_adj[colsums(bin_adj) > 0, colsums(bin_adj) > 0], mode = "undirected")

colors_toy <- colorRampPalette(c("#aa8888", "#ff3333"))(max(degree(toy_g)))
colors_real <- colorRampPalette(c("#aa8888", "#ff3333"))(max(degree(real_g)))


plot(
  toy_g, 
  vertex.size = 2, 
  vertex.color = colors_toy[degree(toy_g)],
  vertex.frame.color = NA, 
  vertex.label = "",
  edge.width = 0.5,
  edge.color = "#aaaaaa"
)

plot(
  real_g, 
  vertex.size = 2, 
  vertex.color = colors_real[degree(real_g)],
  vertex.frame.color = NA, 
  vertex.label = "",
  edge.width = 0.5,
  edge.color = "#aaaaaa"
)

transitivity(toy_g)
transitivity(real_g)

average.path.length(toy_g)
average.path.length(real_g)

```

Scene 5.1: MC for cluster and average path length
```{r}

graph_stats <- function(idfk){
  
  toy_adj <- pred_adj
  binaries <- runif(nrow(toy_adj) * (nrow(toy_adj) - 1) / 2) < upper_tri(toy_adj)
  toy_adj[upper.tri(toy_adj)] <- binaries
  toy_adj <- t(toy_adj)
  toy_adj[upper.tri(toy_adj)] <- binaries
  
  toy_g <- graph_from_adjacency_matrix(toy_adj[colsums(toy_adj) > 0, colsums(toy_adj) > 0], mode = "undirected")
  
  return(
      c(
      transitivity(toy_g),
      average.path.length(toy_g)
    )
  )

}

res <- matrix(unlist(mclapply(1:10000, graph_stats, mc.cores = 12)), ncol = 2, byrow = TRUE)

mean(res[,1])
quantile(res[,1], c(0.025, 0.975), type = 1)

mean(res[,2])
quantile(res[,2], c(0.025, 0.975), type = 1)

```



Scene 6: transmission graph.
```{r}
toy_outbreak <- function() {
  
  # who is vaccinated?
  vaxed <- rbinom(N, 1, p_vax)

  # infection status for each agent (binary)
  inft <- rep(0, N)
  
  # infection time for each agent (seconds)
  inft_time <- rep(Inf, N)
  
  # who we already spread
  checklist <- rep(0, N)
  
  # adjacency
  sim_edgelist <- matrix(nrow = 0, ncol = 2)
  
  
  activity <- rgamma(N, shape = shape, rate = rate)
  sum_activity <- sum(activity)
  
  seed <- sample(N, 1, prob = activity*(1-vaxed))
  inft[seed] <- 1
  inft_time[seed] <- 0
  
  
  while (sum(inft) > sum(checklist)) {
    who <- which((inft - checklist) == 1)
    #print(who)
    
    all_v0 <- inft_time[who]
    neighbors <- lapply(who, get_neighbors, activity = activity, sum_activity = sum_activity)
    
    transmit_times <- mapply(spread, all_v0, neighbors, SIMPLIFY = FALSE)
    
    for (i0 in 1:length(who)) {
      
      secondaries <- neighbors[[i0]][which(transmit_times[[i0]] < inft_time[neighbors[[i0]]])]
      
      inft_time[neighbors[[i0]]] <- pmin(inft_time[neighbors[[i0]]], transmit_times[[i0]])
      
      newmtx <- matrix(c(rep(who[i0], length(secondaries)), secondaries), ncol = 2)
      sim_edgelist <- rbind(sim_edgelist, newmtx)
      
      inft[which(inft_time < sim_duration_secs)] <- 1
    }
    checklist[who] <- 1
    
  }
  
  # get total infections after 4 weeks
  return(sim_edgelist)

}

el <- toy_outbreak()

el[,1] <- paste(el[,1])
el[,2] <- paste(el[,2])

g <- graph_from_edgelist(el)

dists <- as.numeric(distances(g)[el[1,1],] + 1)

colors <- colorRampPalette(c("#ff3333", "#aa8888"))(max(dists))

plot(
  g, 
  vertex.size = 10, 
  vertex.color = colors[dists], 
  vertex.frame.color = NA, 
  vertex.label = "", 
  edge.arrow.size = 0.25
)

```

Scene 7: Histogram of cumulative cases after 4-weeks (incl. index)
```{r}
hist(
  results[,2],
  main = "Histogram of Cumulative Cases",
  xlab = "Cumulative Cases after 4 Weeks"
)

```




Did vaccination change promiscuity?
```{r}
vaxed <- data$user_id[data$out == "VACCINATED"]
when_vaxed <- as.POSIXct(data$time[data$out == "VACCINATED"], origin = "1970-01-01", tz = "America/Denver")

# time-weighted
rate_before <- c()
rate_after <- c()

# when do contacts start/end
min_time <- min(contacts$time)
max_time <- max(contacts$time)

for (i in 1:length(vaxed)) {
  subc <- subset(contacts, user_id == vaxed[i] | peer_id == vaxed[i])
  before <- subset(subc, time < when_vaxed[i])
  after <- subset(subc, time >= when_vaxed[i])
  
  rate_before[i] <- as.numeric(length(before$duration)) / as.numeric(difftime(when_vaxed[i], min_time, units = "secs"))
  rate_after[i] <- as.numeric(length(after$duration)) / as.numeric(difftime(max_time, when_vaxed[i], units = "secs"))
  
}

t.test(rate_after, rate_before)


```














