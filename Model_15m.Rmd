---
title: "Model"
author: "Ivan Specht"
date: "4/6/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

ACT ONE: preliminaries

Scene 1. Load and clean data
```{r}
library(igraph)
library(lubridate)
library(Rfast)
library(mixdist)
library(parallel)
library(ggplot2)
library(ggraph)

data <- read.csv("~/Desktop/OO-paper/histories_BYU.csv")
leger <- read.csv("~/Desktop/OO-paper/participants_BYU.csv")

leger[,"p2p_id"] <- paste(leger[,"p2p_id"])
data[,"peer_id"] <- paste(data[,"peer_id"])

contacts <- subset(data, type == "contact")
contacts$contact_length <- round(milliseconds(contacts$contact_length))
end_time <- contacts$time + contacts$contact_length
contacts <- contacts[, c("user_id", "peer_id", "time")]
contacts <- cbind(contacts, end_time)

convert_peer_ID <- function(x, leger){
  return(leger[which(leger[,"p2p_id"] == x), "id"][1])
}

contacts[,"peer_id"] <- sapply(contacts[,"peer_id"], convert_peer_ID, leger = leger)

contacts$time <- as.POSIXct(contacts$time, origin = "1970-01-01", tz = "America/Denver")
contacts$end_time <- as.POSIXct(contacts$end_time, origin = "1970-01-01", tz = "America/Denver")

lower <- pmin(contacts$user_id, contacts$peer_id)
upper <- pmax(contacts$user_id, contacts$peer_id)

contacts$user_id <- lower
contacts$peer_id <- upper

contacts <- contacts[with(contacts, order(user_id, peer_id, time)), ]

gap <- 30 #seconds

i=2
while (i < nrow(contacts)) {
  if(
    contacts[i,"user_id"] == contacts[i-1,"user_id"] & 
    contacts[i,"peer_id"] == contacts[i-1,"peer_id"] & 
    contacts[i,"time"] < (contacts[i-1,"end_time"] + gap)
  ){
    contacts[i-1, "end_time"] <- max(contacts[i-1, "end_time"], contacts[i, "end_time"])
    contacts <- contacts[-i, ]
  }else{
    i <- i+1
  }
}

contacts <- contacts[with(contacts, order(time)), ]
row.names(contacts) <- 1:nrow(contacts)
duration <- contacts$end_time - contacts$time
contacts <- cbind(contacts, duration)
```

Scene 2. Process "contacts" into time series data useful for epi
```{r}
min_duration <- 60*15 #seconds
ts <- subset(contacts, duration >= min_duration)

# Escapees
escape <- subset(data, out == "ESCAPED")
escape <- escape[, c("user_id", "time")]
escape$time <- as.POSIXct(escape$time, origin = "1970-01-01", tz = "America/Denver")
escape <- escape[order(escape$time),]
row.names(escape) <- 1:nrow(escape)

# Time info for escape

start = as.POSIXct(min(contacts$time), origin = "1970-01-01", tz = "America/Denver")

# get 1 week of contact data
end <- start + weeks(1)

escapees <- escape$user_id[escape$time < end]

# full users
users <- setdiff(leger$id, escapees)


ts <- subset(ts, (user_id %in% users & peer_id %in% users))
ts <- subset(ts, time < end)

# convert to 1-week format

ts$time <- difftime(ts$time, start, units = "secs")
ts$end_time <- difftime(ts$end_time, start, units = "secs")

for (i in which(ts$end_time > 604800)) {
  old <- ts[i,]
  ts$end_time[i] <- 604800
  ts$duration[i] <- 604800 - ts$time[i]
  old$time = 0
  old$end_time <- old$end_time - 604800
  old$duration <- old$end_time
  ts <- rbind(ts, old)
}

ts <- ts[order(ts$time),]
row.names(ts) <- 1:nrow(ts)

ts$time <- seconds(ts$time)
ts$end_time <- seconds(ts$end_time)
```

ACT TWO.

Scene 1. show proportionate mixing assumption (fairly) valid
```{r}

# Adjacency matrix of total duration of contact(s)
real_adj <- matrix(0, nrow = length(users), ncol = length(users))

for (i in 1:length(users)) {
  for (j in i:length(users)) {
    sub <- subset(
      ts,
      (user_id == users[i] & peer_id == users[j]) | (user_id == users[j] & peer_id == users[i])
    )
    real_adj[i,j] <- sum(sub$duration)
    real_adj[j,i] <- sum(sub$duration)
  }
}

# Binary adjacency matrix
bin_adj <- real_adj > 0

# Node degrees
deg <- colsums(bin_adj)

# Predicted adjacency matrix under proportionate mixing, up to a constant
pred_adj <- outer(deg,deg)/sum(deg)
diag(pred_adj) <- 0

# Convert to numeric form...
preds <- as.numeric(pred_adj)
deps <- as.numeric(bin_adj)

# Linear model: decent R^2, low p-value
lmod <- lm(deps~preds+0)
summary(lmod)

# High correlation:
cor(preds, deps)

```

Scene 2: show low correlation between degree and length of contact

```{r}
# predictor variables: proportionate mixing, filtered for nonzero contact length
preds2 <- preds[deps>0]

# predictee variables: total duration of contact, filtered for nonzero contact length
deps2 <- as.numeric(real_adj)[deps>0]

# Linear model: low R^2
lmod2 <- lm(deps2~preds2+0)
summary(lmod2)

# Abysmal correlation
cor(preds2, deps2)
```

ACT THREE. Stochastic bootstrap model.

Scene 1: create bootstrap sampling function for contact times
```{r}
sim_duration <- 4 # WEEKS!!!!
sim_duration_secs <- sim_duration*60*60*24*7

# time of simulation start, seconds
start_secs <- second(start) + 60*minute(start) + 60*60*hour(start)

edgelist <- unique(ts[,1:2])
row.names(edgelist) <- 1:nrow(edgelist)

c_start <- list()
c_end <- list()

total_time <- c()

for (i in 1:nrow(edgelist)) {
  sub <- subset(ts, user_id == edgelist[i,1] & peer_id == edgelist[i,2])
  c_start[[i]] <- as.numeric(sub$time + rep(seconds(weeks(0:(sim_duration))), each = nrow(sub))) # adding extra week for time offset
  c_end[[i]] <- as.numeric(sub$end_time + rep(seconds(weeks(0:(sim_duration))), each = nrow(sub))) # adding extra week for time offset
  total_time[i] <- sum(c_end[[i]] - c_start[[i]])/((sim_duration+1)*60*60*24*7)
}

# v0 is infection time of infector
# i is index of edge contact times

wpar1 <- as.numeric(weibullpar(5, 1.9)[1])
wpar2 <- as.numeric(weibullpar(5, 1.9)[2])

# get time of transmission via UoU with restricted domain
get_time <- function(pstarts, pends, int){
  
  if(length(pstarts) > 1){
    breaks <- pstarts - c(0, pends[1:(length(pends) - 1)])
  }else{
    breaks <- pstarts
  }
  
  divs <- pstarts - cumsum(breaks)
  
  pick <- runif(1, 0, int)
  adj_pick <- pick + sum(breaks[which(divs < pick)])
  
  return(
    qweibull(adj_pick, wpar1, wpar2) * 86400
  )
}

# returns Inf if no transmission occurs
transmission_time <- function(i, neighbor, v0, i0, vaxed, masked, test_rate, start_curfew, end_curfew){
  
  # convert to days
  starts <- (c_start[[i]] - v0)/86400
  ends <- (c_end[[i]] - v0)/86400
  
  # take into account quarantine due to test
  if(daily_tests > 0){
    start_quarantine <- rexp(1, test_rate[i0]) + turnaround
    starts <- starts[starts < start_quarantine]
    if(length(starts) > 0){
      ends <- ends[1:length(starts)]
      ends <- pmin(ends, start_quarantine)
    }else{
      ends <- numeric(0)
    }
  }
  
  if(runif(1) < p_curfew){
    start_times <- (starts + (v0 + start_secs)/86400) %% 1 # time of day, fraction of day
  
    starts <- starts[(start_times < start_curfew) | (start_times >= end_curfew)]
    ends <- ends[(start_times < start_curfew) | (start_times >= end_curfew)]
  }
  
  pstarts <- pweibull(starts, wpar1, wpar2)
  pends <- pweibull(ends, wpar1, wpar2)
  
  int <- sum(pends - pstarts)
  
  prob <- 1 - exp(-lambda*int)
  
  if(masked[neighbor]){
    prob <- prob*0.3
  }
  
  if(masked[i0]){
    prob <- prob*0.3
  }
  
  if(vaxed[neighbor]){
    prob <- prob * 0.05
  }
  
  if(runif(1) < prob){
    return(
      round(
        get_time(pstarts = pstarts, pends = pends, int = int)
      ) + v0
    )
  }else{
    return(Inf)
  }
}

# Stochastic function that spreads virus to neighbors (or doesn't)
spread <- function(v0, neighbors, i0, vaxed, masked, test_rate, start_curfew, end_curfew){
  # uniformly sample a time series for each neighbor, i.e. bootstrap
  indices <- sample(1:nrow(edgelist), size = length(neighbors), replace = TRUE)
  mapply(transmission_time, indices, neighbors, MoreArgs = list(v0 = v0, i0 = i0, vaxed = vaxed, masked = masked, test_rate = test_rate, start_curfew = start_curfew, end_curfew = end_curfew))
}

# Get neighbors stochastically.
get_neighbors <- function(i0, activity, sum_activity){
  which(runif(N) < ((activity[i0] * activity / sum_activity)))
}

# Helper function for getting test rate
get_const <- function(const, activity){
  (sum(1 - exp(-const * activity)) - daily_tests)^2
}


```

Scene 2: Outbreak setup
```{r}
N = 6000

# first, we estimate the nbin params from the OO data.

lik <- function(params, deg){
  -sum(log(dnbinom(deg, params[1], params[2])))
}

est <- suppressWarnings(
  nlm(lik, p = c(mean(deg)^2/(var(deg) - mean(deg)), mean(deg)/var(deg)), deg=deg)
)$estimate

# probability of someone's neighbor being included in sample - original BYU data
p <- 1/3

# p parameter for full number of contacts
p_contact_dist <- p*est[2]/(1-est[2]*(1-p))

# r parameter for full number of contacts
r_contact_dist <- est[1]

# mean + variance in contacts - full sim
mu = (1 - p_contact_dist)*r_contact_dist/p_contact_dist
sigma2 = (1 - p_contact_dist)*r_contact_dist/(p_contact_dist^2)


# Calibrate lambda. First we need to find the average probability of transmission.

variant <- ""

if(variant == "B.1.1.7" | variant == "B.1.351"){
  R0 <- 3
}else{
  R0 <- 2
}

#mean_prob_transmission <- function(lambda){
#  mean(1 - exp(-lambda * total_time))
#}

#mean_n_contacts <- (shape + shape^2)/rate^2


err <- function(lambda){
  (mean(1 - exp(-lambda * total_time)) - R0/((sigma2 + mu^2)/mu - 1))^2
}

lambda <- nlm(err, R0/(((sigma2 + mu^2)/mu - 1) * mean(total_time)))$estimate

### Overdispersion

## Compute current overdispersion based on contacts. See mathematica PGF nb for derivation.

# psi = probability of transmission given contact
psi <- mean(1 - exp(-lambda * total_time))

var_transmissions <- psi*(1-psi)*(1-p_contact_dist)*(1+r_contact_dist)/p_contact_dist + (psi^2)*(1-p_contact_dist)*(1+r_contact_dist)/(p_contact_dist^2)

###------

# get gamma params
shape <- mu^2/(sigma2 - mu)
rate <- mu/(sigma2 - mu)

# probability of being vaccinated
# may want to set a prior?
p_vax <- 0

# probability of wearing mask
p_mask <- 0

# strategic vaccinations?
vax_strategic <- FALSE

# tests per day
daily_tests <- 0

# strategic testing?
test_strategic <- FALSE

# test turnaround time (DAYS)
turnaround <- 0

# probability of abiding by curfew
p_curfew <- 1

# strategic timing of curfew?
curfew_strategic <- TRUE

# when does strategic curfew start, daily? seconds past start time of sim
start_curfew_strategic <- as.numeric(difftime(force_tz(date(start) + hours(10), "America/Denver"), start, units = "secs"))

# when does strategic curfew end, daily? seconds past start time of sim
end_curfew_strategic <- as.numeric(difftime(force_tz(date(start) + hours(13), "America/Denver"), start, units = "secs"))


### a few params from oxford
#gamma_params <- function(mu, sigma){
#  return(c(mu^2/sigma^2, mu/sigma^2))
#}

# https://www.thelancet.com/journals/laninf/article/PIIS1473-3099(20)30230-9/fulltext#sec1
#shape_time_to_symptoms <- 4.23
#rate_time_to_symptoms <- 0.81

#shape_time_to_hospital <- 0.74
#rate_time_to_hospital <- 0.2

```

Scene 3. OUTBREAK!!!
```{r}

outbreak <- function(idfk) {
  
  # activity levels
  activity <- rgamma(N, shape = shape, rate = rate)
  sum_activity <- sum(activity)
  
  #mmm <- outer(activity, activity)/sum_activity
  #diag(mmm) <- 0
  #sum((activity/sum_activity) * colsums(mmm)*mean_prob_transmission(lambda))
  
  #sum((activity/sum_activity)*activity*mean_prob_transmission(lambda))
  
  # who is vaccinated?
  if(vax_strategic){
    vaxed <- 1:N %in% sample(N, round(N*p_vax), prob = activity)
  }else{
    vaxed <- 1:N %in% sample(N, round(N*p_vax))
  }
  
  # Frequency of testing
  if(daily_tests > 0){
    if(test_strategic){
      const <- nlm(get_const, p = daily_tests/sum_activity, activity = activity)$estimate
      test_rate <- 1 - exp(-const * activity)
    }else{
      test_rate <- rep(daily_tests/N, N)
    }
  }else{
    test_rate <- rep(0, N)
  }
  
  # who wears a mask?
  masked <- rbinom(N, 1, p_mask)
  
  # when is curfew?
  
  if(curfew_strategic){
    # when does strategic curfew start, daily? fraction of day
    start_curfew <- 10/24
    
    # when does strategic curfew end, daily? hours into day
    end_curfew <- start_curfew + (3/24)
  }else{
    start_curfew <- runif(1)
    
    end_curfew <- (start_curfew + 3/24) %% 1
    
  }
  
  #######

  # infection status for each agent (binary)
  inft <- rep(0, N)
  
  # infection time for each agent (seconds)
  inft_time <- rep(Inf, N)
  
  # death time for each agent (seconds)
  # death_time <- rep(Inf, N)
  
  # who we already spread
  checklist <- rep(0, N)
  
  # when in the cycle of a week do we start?
  adjust <- floor(runif(1, 0, 604800))
  #adjust <- 0
  
  seed <- sample(N, 1, prob = activity)
  inft[seed] <- 1
  inft_time[seed] <- adjust
  
  first = TRUE
  
  while (sum(inft) > sum(checklist)) {
    who <- which((inft - checklist) == 1)
    #print(who)
    
    all_v0 <- inft_time[who]
    neighbors <- lapply(who, get_neighbors, activity = activity, sum_activity = sum_activity)
    
    transmit_times <- mapply(spread, all_v0, neighbors, who, MoreArgs = list(vaxed = vaxed, masked = masked, test_rate = test_rate, start_curfew = start_curfew, end_curfew = end_curfew), SIMPLIFY = FALSE)
    
    
    for (i0 in 1:length(who)) {
      
      #secondaries <- neighbors[[i0]][which(transmit_times[[i0]] < inft_time[neighbors[[i0]]])]
      #inft_time[secondaries] <- transmit_times[[i0]][which(transmit_times[[i0]] < inft_time[neighbors[[i0]]])]
      
      inft_time[neighbors[[i0]]] <- pmin(inft_time[neighbors[[i0]]], transmit_times[[i0]])
      
      
      # https://www.thelancet.com/journals/laninf/article/PIIS1473-3099(20)30230-9/fulltext#sec1
      # see appendix
      # time to death:
      #https://www.thelancet.com/journals/laninf/article/PIIS1473-3099(20)30769-6/fulltext#sec1
      
      #death_time[secondaries] <- inft_time[secondaries] + rgamma(length(secondaries), shape = 4.23, rate = 0.81) + rgamma(length(secondaries), shape = 4.23, rate = 0.81) + 
      
      #newmtx <- matrix(c(rep(i0, length(secondaries)), secondaries), ncol = 2)
      #sim_edgelist <- rbind(sim_edgelist, newmtx)
      
      inft[which(inft_time < (sim_duration_secs + adjust))] <- 1
    }
    checklist[who] <- 1
    
    if(first == TRUE){
      repro <- sum(inft) - 1
      first <- FALSE
    }
  }
  
  # get total infections after 4 weeks
  return(c(repro, sum(inft)))

}

```

Scene 4. MC simulation.

```{r}

results <- matrix(unlist(mclapply(1:10000, outbreak, mc.cores = 12)), ncol = 2, byrow = TRUE)

```

Scene 5. summary stats
```{r}

R_eff <- mean(results[,1])
R_sd <- sd(results[,1])

mean_cumulative <- mean(results[,2])
median_cumulative <- median(results[,2])
cri_cumulative <- quantile(results[,2], c(0.025, 0.975), type = 1)

R_eff
R_sd

mean_cumulative
median_cumulative
cri_cumulative


est <- suppressWarnings(
  nlm(lik, p = c(mean(results[,1])^2/(var(results[,1]) - mean(results[,1])), mean(results[,1])/var(results[,1])), deg=results[,1])
)$estimate

```

ACT FOUR: Visualization

Visuals list:
- Act 1 viz:
1-- hist numbers of contacts (+ NBin/Bin mixed stat model?)
2-- hist durations of contacts
3-- hist total duration of contacts by person
4-- hist time of contact

- Act 2 viz:
5-- actual contact graph vs. generated contact graph (+ summary stats)

- Act 3 viz:
6-- representative transmission tree
7-- hist of 4-week case counts


Scene 1: number of contacts, 1st and second degree
```{r}
deg2 <- c()
for(i in 1:length(users)){
  deg2[i] <- sum(rowsums(bin_adj[-i, which(bin_adj[i,] == 1), drop = FALSE]) > 0)
}

dat <- data.frame(Contacts = c(deg, deg2), Degree = c(rep("First-degree", length(users)), rep("Second-degree", length(users))))

ggplot(dat, aes(x=Contacts, fill=Degree)) +
  geom_histogram(alpha=0.5, breaks = seq(0,110,2), position = "identity") + 
  labs(
    title = "First- and Second-Degree Contacts, BYU",
    x = "Contacts",
    y = "Frequency"
  ) + theme_minimal()


```

Scene 1.5: scatterplot first/second degree
```{r}



# probability that you're a 2nd-degree contact: 1 - (1-p)^x
# expected 2nd-deg contacts: (n-1)*(1 - (1-p)^x)

get_p <- function(params){
  sum((deg2 - params[1] * (1 - exp(-params[2] * deg)))^2)
}

best_p <- nlm(get_p, c(116,0.06))$estimate

mod_fn <- function(x){
  best_p[1] * (1 - exp(-best_p[2] * x))
}

dat2 <- data.frame(x = deg, y = deg2)

ggplot(dat2, aes(x=x,y=y)) +
  geom_point() + 
  geom_function(fun = mod_fn, color = "red") + 
  theme_minimal() +
  labs(
    title = "First- and Second-Degree Contacts, BYU",
    x = "First-Degree Contacts",
    y = "Second-Degree Contacts"
  )

```

Scene 1.75: representative network graphs
```{r}
# modeled values from above
mod_vals <- sapply(deg, mod_fn)

# biggest underestimate
under <- which.min(deg2 - mod_vals)

# closest estimate
closest <- (deg2 - mod_vals)^2
closest[closest == 0] <- NA
closest <- which.min(closest)

# biggest overestimate
over <- which.max(deg2 - mod_vals)

under_df <- data.frame(x = rep(under, sum(bin_adj[under,])), y = which(bin_adj[under,]))
for(i in which(bin_adj[under,])){
  under_df <- rbind(under_df, data.frame(x = rep(i, sum(bin_adj[i,])), y = which(bin_adj[i,])))
}
under_g <- simplify(graph_from_data_frame(under_df, directed = FALSE))

ggraph(under_g, layout = 'kk') + 
  geom_edge_link(width = 0.2, alpha = 0.5) + 
  geom_node_point(
    aes(
      color = factor(distances(under_g, to = paste(under))),
      size = deg[as.numeric(names(V(under_g)))]
      )
    ) +
  scale_size(name = "Node Degree", range = c(1,10)) +
  scale_color_discrete(name = "Contact Degree") +
  theme(
    panel.background = element_rect(fill = "transparent", colour = NA),
    plot.background = element_rect(fill = "transparent", colour = NA),
    legend.key=element_blank()
  )

closest_df <- data.frame(x = rep(closest, sum(bin_adj[closest,])), y = which(bin_adj[closest,]))
for(i in which(bin_adj[closest,])){
  closest_df <- rbind(closest_df, data.frame(x = rep(i, sum(bin_adj[i,])), y = which(bin_adj[i,])))
}
closest_g <- simplify(graph_from_data_frame(closest_df, directed = FALSE))

ggraph(closest_g, layout = 'kk') + 
  geom_edge_link(width = 0.2, alpha = 0.5) + 
  geom_node_point(
    aes(
      color = factor(distances(closest_g, to = paste(closest))),
      size = deg[as.numeric(names(V(closest_g)))]
      )
    ) +
  scale_size(name = "Node Degree", range = c(1,10)) +
  scale_color_discrete(name = "Contact Degree") +
  theme(
    panel.background = element_rect(fill = "transparent",colour = NA),
    plot.background = element_rect(fill = "transparent",colour = NA),
    legend.key=element_blank()
  )

over_df <- data.frame(x = rep(over, sum(bin_adj[over,])), y = which(bin_adj[over,]))
for(i in which(bin_adj[over,])){
  over_df <- rbind(over_df, data.frame(x = rep(i, sum(bin_adj[i,])), y = which(bin_adj[i,])))
}
over_g <- simplify(graph_from_data_frame(over_df, directed = FALSE))

ggraph(over_g, layout = 'kk') + 
  geom_edge_link(width = 0.2, alpha = 0.5) + 
  geom_node_point(
    aes(
      color = factor(distances(over_g, to = paste(over))),
      size = deg[as.numeric(names(V(over_g)))]
      )
    ) +
  scale_size(name = "Node Degree", range = c(1,10)) +
  scale_color_discrete(name = "Contact Degree") +
  theme(
    panel.background = element_rect(fill = "transparent",colour = NA),
    plot.background = element_rect(fill = "transparent",colour = NA),
    legend.key=element_blank()
  )

```


Scene 2: durations of contacts
```{r}

ggplot(data.frame(t = as.numeric(ts$duration)), aes(x=t)) + 
  geom_histogram(breaks = seq(0,110000, 1000)) + 
  labs(
    title = "Duration of Contact, BYU",
    x = "Time (seconds)",
    y = "Frequency"
  )

# parameter estimation

lik <- function(params, deg){
  -sum(log(dnbinom(deg, params[1], params[2])))
}

est <- suppressWarnings(
  nlm(lik, p = c(mean(deg)^2/(var(deg) - mean(deg)), mean(deg)/var(deg)), deg=deg)
)

```


Scene 3: total duration of all contacts by person

```{r}

ggplot(data.frame(t = colsums(real_adj)[colsums(real_adj) != 0]), aes(x=t)) + 
  geom_histogram(breaks = seq(0,450000, 5000)) + 
  labs(
    title = "Total Duration of all Contacts by Person, BYU",
    x = "Time (seconds)",
    y = "Frequency"
  ) 

```



Scene 4: when people are interacting
```{r}
hour_interactions <- c()
hour_breaks <- seconds(seq(0, 604800, 3600))
for (i in 2:length(hour_breaks)) {
  sub <- subset(ts, hour_breaks[i-1] <= time & time < hour_breaks[i])
  sub <- unique(sub[,1:2])
  hour_interactions[i-1] <- nrow(sub)
}

timebins <- start + hour_breaks[1:(length(hour_breaks) - 1)]

ggplot(data.frame(t = timebins, count = hour_interactions), aes(x=t, y = count)) + 
  geom_line() + 
  labs(
    title = "Timing of Interactions, BYU",
    x = "Time",
    y = "Number of Interactions"
  ) + 
  scale_x_datetime(breaks = "12 hours", date_labels = "%a %h %d %H:%M") + 
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))


```




Scene 5: actual graph vs. predicted graph example

```{r}
toy_adj <- pred_adj
binaries <- runif(nrow(toy_adj) * (nrow(toy_adj) - 1) / 2) < upper_tri(toy_adj)
toy_adj[upper.tri(toy_adj)] <- binaries
toy_adj <- t(toy_adj)
toy_adj[upper.tri(toy_adj)] <- binaries

toy_g <- graph_from_adjacency_matrix(toy_adj[colsums(toy_adj) > 0, colsums(toy_adj) > 0], mode = "undirected")
real_g <- graph_from_adjacency_matrix(bin_adj[colsums(bin_adj) > 0, colsums(bin_adj) > 0], mode = "undirected")

colors_toy <- colorRampPalette(c("#aa8888", "#ff3333"))(max(degree(toy_g)))
colors_real <- colorRampPalette(c("#aa8888", "#ff3333"))(max(degree(real_g)))


plot(
  toy_g, 
  vertex.size = 2, 
  vertex.color = colors_toy[degree(toy_g)],
  vertex.frame.color = NA, 
  vertex.label = "",
  edge.width = 0.5,
  edge.color = "#aaaaaa"
)

plot(
  real_g, 
  vertex.size = 2, 
  vertex.color = colors_real[degree(real_g)],
  vertex.frame.color = NA, 
  vertex.label = "",
  edge.width = 0.5,
  edge.color = "#aaaaaa"
)

transitivity(toy_g)
transitivity(real_g)

average.path.length(toy_g)
average.path.length(real_g)

```


Scene 5.1: MC for cluster and average path length
```{r}

graph_stats <- function(idfk){
  
  toy_adj <- pred_adj
  binaries <- runif(nrow(toy_adj) * (nrow(toy_adj) - 1) / 2) < upper_tri(toy_adj)
  toy_adj[upper.tri(toy_adj)] <- binaries
  toy_adj <- t(toy_adj)
  toy_adj[upper.tri(toy_adj)] <- binaries
  
  toy_g <- graph_from_adjacency_matrix(toy_adj[colsums(toy_adj) > 0, colsums(toy_adj) > 0], mode = "undirected")
  
  return(
      c(
      transitivity(toy_g),
      average.path.length(toy_g)
    )
  )

}

res <- matrix(unlist(mclapply(1:10000, graph_stats, mc.cores = 12)), ncol = 2, byrow = TRUE)

mean(res[,1])
quantile(res[,1], c(0.025, 0.975), type = 1)

mean(res[,2])
quantile(res[,2], c(0.025, 0.975), type = 1)

```


Scene 6: transmission graph.
```{r}
toy_outbreak <- function() {
  
  # who is vaccinated?
  vaxed <- rbinom(N, 1, p_vax)

  # infection status for each agent (binary)
  inft <- rep(0, N)
  
  # infection time for each agent (seconds)
  inft_time <- rep(Inf, N)
  
  # who we already spread
  checklist <- rep(0, N)
  
  # adjacency
  sim_edgelist <- matrix(nrow = 0, ncol = 2)
  
  
  activity <- rgamma(N, shape = shape, rate = rate)
  sum_activity <- sum(activity)
  
  seed <- sample(N, 1, prob = activity*(1-vaxed))
  inft[seed] <- 1
  inft_time[seed] <- 0
  
  
  while (sum(inft) > sum(checklist)) {
    who <- which((inft - checklist) == 1)
    #print(who)
    
    all_v0 <- inft_time[who]
    neighbors <- lapply(who, get_neighbors, activity = activity, sum_activity = sum_activity)
    
    transmit_times <- mapply(spread, all_v0, neighbors, SIMPLIFY = FALSE)
    
    for (i0 in 1:length(who)) {
      
      secondaries <- neighbors[[i0]][which(transmit_times[[i0]] < inft_time[neighbors[[i0]]])]
      
      inft_time[neighbors[[i0]]] <- pmin(inft_time[neighbors[[i0]]], transmit_times[[i0]])
      
      newmtx <- matrix(c(rep(who[i0], length(secondaries)), secondaries), ncol = 2)
      sim_edgelist <- rbind(sim_edgelist, newmtx)
      
      inft[which(inft_time < sim_duration_secs)] <- 1
    }
    checklist[who] <- 1
    
  }
  
  # get total infections after 4 weeks
  return(sim_edgelist)

}

el <- toy_outbreak()

el[,1] <- paste(el[,1])
el[,2] <- paste(el[,2])

g <- graph_from_edgelist(el)

dists <- as.numeric(distances(g)[el[1,1],] + 1)

colors <- colorRampPalette(c("#ff3333", "#aa8888"))(max(dists))

plot(
  g, 
  vertex.size = 5, 
  vertex.color = colors[dists], 
  vertex.frame.color = NA, 
  vertex.label = "", 
  edge.arrow.size = 0.25
)

```

Scene 7: Histogram of cumulative cases after 4-weeks (incl. index)
```{r}
hist(
  results[,2],
  main = "Histogram of Cumulative Cases",
  xlab = "Cumulative Cases after 4 Weeks"
)

```

Scene 8: Social promiscuity

```{r}
full_users <- leger$id

full_hour_breaks <- seconds(seq(0, as.numeric(difftime(max(contacts$end_time), min(contacts$time), units = "secs")), 3600))

sim_breaks <- round(start, units = "hours") + full_hour_breaks

clean_contacts <- contacts
i = 1
while (i <= nrow(clean_contacts)) {
  if(floor_date(clean_contacts$time[i], unit = "hours") != floor_date(clean_contacts$end_time[i], unit = "hours")){
    newrow <- clean_contacts[i, ]
    newrow$time <- floor_date(clean_contacts$end_time[i], unit = "hours")
    newrow$duration <- newrow$end_time - newrow$time
    clean_contacts <- rbind(clean_contacts, newrow)
    clean_contacts$end_time[i] <- floor_date(clean_contacts$end_time[i], unit = "hours")
    clean_contacts$duration[i] <- clean_contacts$end_time[i] - clean_contacts$time[i]
    row.names(clean_contacts) <- 1:nrow(clean_contacts)
  }
  i <- i + 1
}
clean_contacts <- clean_contacts[with(clean_contacts, order(user_id, peer_id, time)), ]
row.names(clean_contacts) <- 1:nrow(clean_contacts)

promiscuity <- data.frame()
promiscuity <- rbind(promiscuity, rep(0, length(full_users)))

prom_mtx <- matrix(0, nrow = length(full_users), ncol = length(full_users))

for (i in 2:(length(sim_breaks))) {
  print(i)
  subc <- subset(clean_contacts, sim_breaks[i-1] <= time & time < sim_breaks[i])
  subc <- subc[,c("user_id", "peer_id", "duration")]
  
  combs <- unique(subc[, c("user_id", "peer_id")])
  
  for (r in 1:nrow(combs)) {
    who <- c(combs$user_id[r], combs$peer_id[r])
    subsubc <- subset(subc, user_id == who[1] & peer_id == who[2])
    prom_mtx[which(full_users == who[1]), which(full_users == who[2])] <- prom_mtx[which(full_users == who[1]), which(full_users == who[2])] + sum(subsubc$duration)
    prom_mtx[which(full_users == who[2]), which(full_users == who[1])] <- prom_mtx[which(full_users == who[2]), which(full_users == who[1])] + sum(subsubc$duration)
  }
  promiscuity <- rbind(promiscuity, colsums(1 - exp(-0.001*prom_mtx)))
}

promiscuity <- cbind(sim_breaks, promiscuity)
colnames(promiscuity) <- c("time", paste0("user_", full_users))

write.csv(promiscuity, "promiscuity_CMU.csv")

```

Scene 9: hists of case count distribution
```{r}

ggg <- ggplot(all_results, aes(x=Cumulative_Cases, fill=Curfew)) +
  geom_histogram(alpha=0.5, breaks = seq(0,600,10), position = "identity") + 
  labs(
    title = "Cumulative Cases, 4 Weeks",
    x = "Cumulative Cases",
    y = "Frequency"
  )
ggg


```





LOL
```{r}
andres <- outer(activity, activity)
diag(andres) <- 0
andres <- andres/sum(activity)

bins <- (runif(N*(N-1)/2) < upper_tri(andres))

andres[upper.tri(andres)] <- bins
andres <- t(andres)
andres[upper.tri(andres)] <- bins

write.csv(as.data.frame(andres), "andres.csv")

```













